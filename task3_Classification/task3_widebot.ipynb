{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data and concatenate multiple csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming all CSV files are in the same directory\n",
    "data_directory = \"C:/Users/LENOVO/Downloads/archive/stories/\"\n",
    "csv_files = [file for file in os.listdir(data_directory) if file.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty list to store DataFrames from each CSV\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(data_directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "story_data = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>story</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>f06aa998054e11eba66e646e69d991ea</td>\n",
       "      <td>\"بيت الشعر\" يسائل وزير الثقافة عن كوابيس سوداء</td>\n",
       "      <td>الجمعة 02 أكتوبر 2020 - 23:19</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>وجه \"بيت الشعر في المغرب\" إلى وزير الثقافة وال...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>f1cf1b9c054e11ebb718646e69d991ea</td>\n",
       "      <td>مهرجان \"سينما المؤلّف\" يستحضر روح ثريا جبران</td>\n",
       "      <td>الجمعة 02 أكتوبر 2020 - 07:26</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>في ظلّ استمرار حالة الطوارئ الصحية المرتبطة بج...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>f2d282a4054e11eb800f646e69d991ea</td>\n",
       "      <td>فيلم \"بدون عنف\" لهشام العسري ..\"كعب الحذاء ووا...</td>\n",
       "      <td>الجمعة 02 أكتوبر 2020 - 04:00</td>\n",
       "      <td>عفيفة الحسينات*</td>\n",
       "      <td>تشير مشاهدة فيلم قصير ضمن الثلاثية الأخيرة للم...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>f3f46cac054e11eba403646e69d991ea</td>\n",
       "      <td>\"تنين ووهان\" .. مريم أيت أحمد توقِّع أولى \"روا...</td>\n",
       "      <td>الجمعة 02 أكتوبر 2020 - 02:00</td>\n",
       "      <td>حاورَها: وائل بورشاشن</td>\n",
       "      <td>مِن قَلب أيّام \"الحَجْر\"، رأتِ النّورَ الفصول ...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>f50f0476054e11eba31b646e69d991ea</td>\n",
       "      <td>مسكر يتخلّى عن دعم \"الوزارة\" بسبب \"الجمهور\"</td>\n",
       "      <td>الخميس 01 أكتوبر 2020 - 19:40</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>أعلن الفنان المغربيّ سعيد مسكر تخليه عن مبلغ ا...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                id  \\\n",
       "0           0  f06aa998054e11eba66e646e69d991ea   \n",
       "1           1  f1cf1b9c054e11ebb718646e69d991ea   \n",
       "2           2  f2d282a4054e11eb800f646e69d991ea   \n",
       "3           3  f3f46cac054e11eba403646e69d991ea   \n",
       "4           4  f50f0476054e11eba31b646e69d991ea   \n",
       "\n",
       "                                               title  \\\n",
       "0     \"بيت الشعر\" يسائل وزير الثقافة عن كوابيس سوداء   \n",
       "1       مهرجان \"سينما المؤلّف\" يستحضر روح ثريا جبران   \n",
       "2  فيلم \"بدون عنف\" لهشام العسري ..\"كعب الحذاء ووا...   \n",
       "3  \"تنين ووهان\" .. مريم أيت أحمد توقِّع أولى \"روا...   \n",
       "4        مسكر يتخلّى عن دعم \"الوزارة\" بسبب \"الجمهور\"   \n",
       "\n",
       "                            date                 author  \\\n",
       "0  الجمعة 02 أكتوبر 2020 - 23:19       هسبريس من الرباط   \n",
       "1  الجمعة 02 أكتوبر 2020 - 07:26       هسبريس من الرباط   \n",
       "2  الجمعة 02 أكتوبر 2020 - 04:00        عفيفة الحسينات*   \n",
       "3  الجمعة 02 أكتوبر 2020 - 02:00  حاورَها: وائل بورشاشن   \n",
       "4  الخميس 01 أكتوبر 2020 - 19:40       هسبريس من الرباط   \n",
       "\n",
       "                                               story           topic  \n",
       "0  وجه \"بيت الشعر في المغرب\" إلى وزير الثقافة وال...  art-et-culture  \n",
       "1  في ظلّ استمرار حالة الطوارئ الصحية المرتبطة بج...  art-et-culture  \n",
       "2  تشير مشاهدة فيلم قصير ضمن الثلاثية الأخيرة للم...  art-et-culture  \n",
       "3  مِن قَلب أيّام \"الحَجْر\"، رأتِ النّورَ الفصول ...  art-et-culture  \n",
       "4  أعلن الفنان المغربيّ سعيد مسكر تخليه عن مبلغ ا...  art-et-culture  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'title', 'date', 'author', 'story', 'topic'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 'story' and 'title' columns to create a new feature\n",
    "story_data['title_story'] = story_data['title'] + '@@' + story_data['story']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X = story_data['title_story']\n",
    "y = story_data['topic']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_support_vector_classifier(X_train,y_train, kernel_type='linear', min_df=1, max_df=1.0, max_features=None):\n",
    "   \n",
    "    # Create a TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df, max_features=max_features)\n",
    "\n",
    "    # Vectorize the training data\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "\n",
    "    # Train a Naive Bayes classifier\n",
    "    classifier = SVC(C=1,kernel=kernel_type, random_state=42)\n",
    "\n",
    "    classifier.fit(X_train_vec, y_train)\n",
    "\n",
    "    return classifier, vectorizer, X_test, y_test\n",
    "\n",
    "def evaluate_classifier(classifier, vectorizer, X_test, y_test):\n",
    "    # Vectorize the test data\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = classifier.predict(X_test_vec)\n",
    "\n",
    "    # Calculate and print the performance metrics\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    art-et-culture       0.90      0.90      0.90       206\n",
      "          economie       0.83      0.86      0.84       202\n",
      "      faits-divers       0.95      0.96      0.95       184\n",
      "marocains-du-monde       0.89      0.90      0.89       214\n",
      "            medias       0.98      0.91      0.94       197\n",
      "           orbites       0.72      0.75      0.74       204\n",
      "         politique       0.85      0.84      0.84       210\n",
      "           regions       0.79      0.83      0.81       178\n",
      "           societe       0.76      0.74      0.75       198\n",
      "             sport       0.99      0.96      0.98       194\n",
      "         tamazight       0.97      0.95      0.96       213\n",
      "\n",
      "          accuracy                           0.87      2200\n",
      "         macro avg       0.87      0.87      0.87      2200\n",
      "      weighted avg       0.88      0.87      0.87      2200\n",
      "\n",
      "Accuracy: 0.8731818181818182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8731818181818182"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjust these parameters as needed\n",
    "kernel_type = 'linear'\n",
    "min_df = 1\n",
    "max_df = 1.0\n",
    "max_features = None\n",
    "test_size = 0.2\n",
    "\n",
    "# Train the classifier\n",
    "classifier, vectorizer, X_test, y_test = train_support_vector_classifier(X_train,y_train,kernel_type=kernel_type, min_df=min_df, max_df=max_df, max_features=max_features)\n",
    "\n",
    "# Evaluate the classifier\n",
    "evaluate_classifier(classifier, vectorizer, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision: Precision is the ratio of true positive predictions to the total number of positive predictions made by the classifier. In this case,(e.g., \"art-et-culture\"), precision measures how many of the stories predicted as \"art-et-culture\" are actually correctly classified. Higher precision indicates a lower false positive rate for that class.\n",
    "\n",
    "Recall: Recall, also known as sensitivity or true positive rate, is the ratio of true positive predictions to the total number of actual positive instances in the dataset. In this case, for a specific class, recall measures how many of the actual \"art-et-culture\" articles are correctly identified by the classifier. Higher recall indicates a lower false negative rate for that class.\n",
    "\n",
    "F1-score: The F1-score is the harmonic mean of precision and recall and provides a balance between the two metrics. It is useful when there is an uneven class distribution, as it considers both false positives and false negatives. It is a single metric that summarizes the model's performance for a specific class, with a higher value indicating better performance.\n",
    "\n",
    "Support: Support is the number of instances (stories) belonging to each class in the test set. It provides context on the distribution of classes and indicates the relative size of each class.\n",
    "\n",
    "Accuracy: Accuracy is the overall correct predictions made by the classifier, divided by the total number of instances in the test set. It measures the overall correctness of the model's predictions and is a common metric for multi-class classification tasks.\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some enhancements that can achieve better results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Text Preprocessing:\n",
    "\n",
    "a. Stemming: Stemming is the process of reducing words to their root form by removing suffixes and prefixes. For example, \"running\" and \"runs\" both reduce to \"run.\" Stemming can help reduce the dimensionality of the feature space and speed up model training, but it may not always produce meaningful words.\n",
    "\n",
    "   b. Lemmatization: Lemmatization is similar to stemming but involves reducing words to their base or dictionary form (lemma). Unlike stemming, lemmatization ensures that the resulting word is a meaningful word. For example, \"running\" and \"runs\" both lemmatize to \"run.\" Lemmatization may be more suitable when maintaining the semantic meaning of words is important.\n",
    "\n",
    "   c. Removing Stopwords: Stopwords are common words (e.g., \"the,\" \"is,\" \"and\") that often appear frequently in text but carry little semantic value. Removing stopwords can help reduce noise in the data and improve the efficiency of the model by focusing on more informative words.\n",
    "\n",
    "   By experimenting with different combinations of stemming, lemmatization, and stopwords removal, you can assess how each preprocessing technique affects the model's accuracy, precision, recall, and other performance metrics.\n",
    "\n",
    "2. Domain-Specific Embeddings:\n",
    "While pre-trained word embeddings like Word2Vec, GloVe, and FastText capture general semantic information across various domains, they may not fully capture the specific context and semantics of your domain. If you have a specialized domain like legal, medical, or technical texts, the language and vocabulary used in these domains may differ significantly from general language.\n",
    "\n",
    "To address this, consider using domain-specific word embeddings. These embeddings are trained on a large corpus of text data specific to your domain, capturing context and semantic information that is relevant to your domain. By leveraging domain-specific embeddings, the model may better understand and represent the nuances and domain-specific terms, potentially leading to improved performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
